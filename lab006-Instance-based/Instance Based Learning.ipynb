{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size=\"6\">Instance Based Learning</font><a class=\"anchor\"><a id='toc'></a></b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to apply Instance Based Classifiers in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "# TOC<a class=\"anchor\"><a id='toc'></a></b><br>\n",
    "* [<font color='#E8800A'>1. KNN Classifier</font>](#first-bullet) <br>\n",
    "    - 1.1. Methods\n",
    "    - 1.2. Changing the number of neighbors\n",
    "    - 1.3. Changing the algorithm : Brute Force Vs. KDTree\n",
    "    - 1.4. Change the distance metric\n",
    "    - 1.5. Using a Weighted Distance\n",
    "- [<font color='#E8800A'>2. KNN Imputer</font>](#third-bullet)<br>\n",
    "- [<font color='#E8800A'>3. KNN Regression (EXERCISE)</font>](#second-bullet)<br>\n",
    "    - 3.1. Methods\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>1. KNN Classifier</font> <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "  [Back to TOC](#toc)\n",
    "  \n",
    "In the classification problem, we are going to use the Iris dataset - this is perhaps the best known database to be found in the pattern recognition literature. The attributes in the dataset are:\n",
    "\n",
    "- __SepalLengthCm:__ sepal length in cm\n",
    "- __SepalWidthCm:__ sepal width in cm\n",
    "- __PetalLengthCm:__ petal length in cm\n",
    "- __PetalWidthCm:__ petal width in cm\n",
    "- __Target:__ Iris Setosa(Class 0), Iris Versicolour (Class 1), Iris Virginica (Class 2)\n",
    "\n",
    "\n",
    "<img src=\"Images\\iris.png\" style=\"height:300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1:__ Import KNeighborsClassifier from sklearn.neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:48.127943Z",
     "start_time": "2020-10-30T11:01:45.225310Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2:__ Import Iris Dataset and check the structure of this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:49.757920Z",
     "start_time": "2020-10-30T11:01:48.136085Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iris = pd.read_csv('Iris.csv')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__ Assign to the object `data` the values from iris excepting the dependent variable and assign to the object `target` the independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:49.879930Z",
     "start_time": "2020-10-30T11:01:49.875040Z"
    }
   },
   "outputs": [],
   "source": [
    "data = iris.drop(['Target'], axis=1)\n",
    "target = iris['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 4:__ Import train_test_split from sklearn.model_selection and split the dataset tugas into X_train, X_val, y_train and y_val, defining `train_size` as 0.75 , `random_state`equal to 5 and `stratify` by the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:49.914801Z",
     "start_time": "2020-10-30T11:01:49.902714Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, target, train_size=0.75, stratify = target, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 5:__ Using KNeighborsClassifier, create a Nearest Neighbor classifier instance called modelKNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:49.944823Z",
     "start_time": "2020-10-30T11:01:49.940832Z"
    }
   },
   "outputs": [],
   "source": [
    "modelKNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Methods in KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 6:__ Use the `.fit()`method of model to fit the model to the array of points `X_train` and `y_train`,i.e., associate the argument keyword `X` to `X_train` and `y` to `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:49.966764Z",
     "start_time": "2020-10-30T11:01:49.946816Z"
    }
   },
   "outputs": [],
   "source": [
    "modelKNN.fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 7:__ Use the `.predict()` method of modelKNN to perform classification in `X_train` and assign to the object `labels_train`. Do the same for `X_val` and assign to the object `labels_val`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:49.991735Z",
     "start_time": "2020-10-30T11:01:49.968758Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_train = modelKNN.predict(X_train)\n",
    "labels_val = modelKNN.predict(X_val)\n",
    "labels_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 8:__ Use the `.predict_proba()` method of modelKNN to obtain the probability estimates for the `X_val`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.006658Z",
     "start_time": "2020-10-30T11:01:49.994431Z"
    }
   },
   "outputs": [],
   "source": [
    "modelKNN.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 9:__ Use the `.score()` method of modelKNN to obtain the mean accuracy of the model in the training data and in the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.035559Z",
     "start_time": "2020-10-30T11:01:50.008651Z"
    }
   },
   "outputs": [],
   "source": [
    "print(modelKNN.score(X_train, y_train))\n",
    "print(modelKNN.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the results of Step 9 we can verify that the accuracy of the model is higher in the train dataset. We are in a case of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 10:__ Use the `.kneighbors()` method of modelKNN to finds the K-neighbors of a point, and define the arguments `X=X_val`. Using this method, you will obtain an array representing the lengths between a point to the five nearest neighbors, and the indices of the nearest points in the population matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.069965Z",
     "start_time": "2020-10-30T11:01:50.054016Z"
    }
   },
   "outputs": [],
   "source": [
    "modelKNN.kneighbors(X = X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Change the number of neighbors (k) (default = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 11:__ We can change the number of neighbors to consider in order to classify new instances to 3 by creating a new KNN classifier where `n_neighbors=3`. Create a new instance of KNeighborsClassifier named as `modelKNN3` with `n_neighbors=3` and fit to your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.168556Z",
     "start_time": "2020-10-30T11:01:50.164597Z"
    }
   },
   "outputs": [],
   "source": [
    "modelKNN3 = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 12:__ Use the `.predict()` method of modelKNN3 to perform classification in `X_train` and assign to the object `labels_train`. Do the same for `X_val` and assign to the object `labels_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.213554Z",
     "start_time": "2020-10-30T11:01:50.192883Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_train = modelKNN3.predict(X_train)\n",
    "labels_val = modelKNN3.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 13:__ Use the `.predict_proba()` method of modelKNN5 to obtain the probability estimates for the `X_val`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.224940Z",
     "start_time": "2020-10-30T11:01:50.214552Z"
    }
   },
   "outputs": [],
   "source": [
    "modelKNN3.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 14:__ Use the `.score()` method of modelKNN3 to obtain the mean accuracy of the model in the training and the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.256035Z",
     "start_time": "2020-10-30T11:01:50.226982Z"
    }
   },
   "outputs": [],
   "source": [
    "print(modelKNN3.score(X_train, y_train))\n",
    "print(modelKNN3.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "### <font color='#900C3F'>!! What is the impact of changing the number of neighbors? !!</font>\n",
    "\n",
    "Compare the results between a KNN model where the number of neighbors is small and when the number of neighbors is large:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Number of Neighbors = 1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKNN1 = KNeighborsClassifier(n_neighbors=1).fit(X = X_train, y = y_train)\n",
    "print(modelKNN1.score(X_train, y_train))\n",
    "print(modelKNN1.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Number of Neighbors = 3__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKNN3 = KNeighborsClassifier(n_neighbors=3).fit(X = X_train, y = y_train)\n",
    "print(modelKNN3.score(X_train, y_train))\n",
    "print(modelKNN3.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Number of Neighbors = 100__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKNN100 = KNeighborsClassifier(n_neighbors=100).fit(X = X_train, y = y_train)\n",
    "print(modelKNN100.score(X_train, y_train))\n",
    "print(modelKNN100.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 15:__ To identify the optimal number of neighbors to select, create a loop where you test the mean accuracy score in validation, where the number of neighbors range from 1 to 20. Check the number of neighbors to keep and the f1 score in the train and validation for that number of neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberK_list=np.arange(1,21)\n",
    "high_score=0\n",
    "nof=0           \n",
    "score_list_train =[]\n",
    "score_list_val =[]\n",
    "for n in numberK_list:\n",
    "    model = KNeighborsClassifier(n_neighbors = n).fit(X_train, y_train)\n",
    "    score_train = model.score(X_train, y_train)\n",
    "    score_val = model.score(X_val, y_val)\n",
    "    score_list_train.append(score_train)\n",
    "    score_list_val.append(score_val)\n",
    "    \n",
    "    if(score_val>high_score):\n",
    "        high_score = score_val\n",
    "        nof = numberK_list[n-1]\n",
    "print(\"Best number of neighbors: %d\" %nof)\n",
    "print(\"Mean accuracy in train with %d neighbors: %f\" % (nof, score_list_train[nof-1]))\n",
    "print(\"Mean accuracy in validation with %d neighbors: %f\" % (nof, high_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "#### __Conclusion:__ <br>\n",
    "1) A small number of neighbors could lead to overfitting; <br>\n",
    "2) A big number of neighbors can lead to underfitting.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Change the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 16:__ We can change the algorithm used from `auto` to a specific option, for example the k-d tree by creating a new KNN classifier where `algorithm='kd_tree'`. The theoretical KNN basic algorithm is considered as a brute-force algorithm (algorithm = 'brute). Let's see the difference in speed, comparing in a bigger dataset the time it takes to train and predict in the traditional method and using KDTree. <br> <br>\n",
    "Create a new instance of KNeighborsClassifier named as `modelKNNT` with `algorithm='kd_tree'` and fit to your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.285932Z",
     "start_time": "2020-10-30T11:01:50.274997Z"
    }
   },
   "outputs": [],
   "source": [
    "modelKNNT = KNeighborsClassifier(algorithm='kd_tree').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 17:__ Use the `.predict()` method of modelKNNT to perform classification in `X_train` and assign to the object `labels_train`. Do the same for `X_val` and assign to the object `labels_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.333284Z",
     "start_time": "2020-10-30T11:01:50.306092Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_train = modelKNNT.predict(X_train)\n",
    "labels_val = modelKNNT.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 18:__ Use the `.score()` method of modelKNNT to obtain the mean accuracy of the model in the training and the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.367749Z",
     "start_time": "2020-10-30T11:01:50.349588Z"
    }
   },
   "outputs": [],
   "source": [
    "modelKNNT.score(X_train, y_train)\n",
    "modelKNNT.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "### <font color='#900C3F'>!! What is the difference between using the traditional KNN and the KDTree? !!</font>\n",
    "\n",
    "Compare the results between a KNN model where the algorithm applied is brute-force and a KDTree in a dataset with 20000 observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "new = pd.read_csv('Skin_NonSkin.txt', sep=\"\\t\", header=None)\n",
    "new = new.iloc[:20000,:]\n",
    "data = new.iloc[:,:-1]\n",
    "target = new.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Algorithm = 'brute'__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_brute = KNeighborsClassifier(algorithm = 'brute').fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "labels_train = KNN_brute.predict(data)\n",
    "print('Time:', time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Algorithm = 'kd_tree'__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KDD_tree = KNeighborsClassifier(algorithm='kd_tree').fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "labels_train = KDD_tree.predict(data)\n",
    "print('Time:', time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "#### __Conclusion:__ <br>\n",
    "In a dataset with only 20000 observations, the KDTree is around 14 times faster than the traditional algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Change the distance metric (default = Euclidean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 19:__ We can change the distance used from `Euclidean` to others such as the `Manhattan` distance by creating a new KNN classifier where `metric = \"manhattan\"'`. Note that the default is Minkowski with a default parameter of `p = 2`, so in practice the default distance is Euclidean. <br><br>\n",
    "\n",
    "Create a new instance of KNeighborsClassifier named as `modelKNNM` with `metric = 'manhattan'` and fit to your training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.389418Z",
     "start_time": "2020-10-30T11:01:50.385830Z"
    }
   },
   "outputs": [],
   "source": [
    "modelKNNM = KNeighborsClassifier(metric = 'manhattan').fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 20:__ Use the `.predict()` method of modelKNNM to perform classification in `X_train` and assign to the object `labels_train`. Do the same for `X_val` and assign to the object `labels_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.427803Z",
     "start_time": "2020-10-30T11:01:50.404578Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_train = modelKNNM.predict(X_train)\n",
    "labels_val = modelKNNM.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 21:__ Use the `.score()` method of modelKNNM to obtain the mean accuracy of the model in the training and the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.464029Z",
     "start_time": "2020-10-30T11:01:50.441990Z"
    }
   },
   "outputs": [],
   "source": [
    "print(modelKNNM.score(X_train, y_train))\n",
    "print(modelKNNM.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "### <font color='#900C3F'>!!What is the difference between using the Euclidean or Manhattan Distance? !!</font>\n",
    "\n",
    "In https://bib.dbvis.de/uploadedFiles/155.pdf, the authors defend that Manhattan distance may be preferable to Euclidean distance for the case of high dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Distance weighted KNN (default = 'uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 22:__ By default, each neighbor will have the same weight in the final prediction (`weights = 'uniform'`). Define the parameter `weights = 'distance'` so the nearest neighbors have more influence/weight on the prediction than the farthest ones. <br> The name of the model is defined as `modelKNNW`. Fit the instance to your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.489771Z",
     "start_time": "2020-10-30T11:01:50.484808Z"
    }
   },
   "outputs": [],
   "source": [
    "modelKNNW= KNeighborsClassifier(weights='distance').fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 23:__ Use the `.predict()` method of modelKNNW to perform classification in `X_train` and assign to the object `labels_train`. Do the same for `X_val` and assign to the object `labels_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.527019Z",
     "start_time": "2020-10-30T11:01:50.512070Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_train = modelKNNW.predict(X_train)\n",
    "labels_val = modelKNNW.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 24:__ Use the `.predict_proba()` method of modelKNNW to obtain the probability estimates for the `X_val`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.545291Z",
     "start_time": "2020-10-30T11:01:50.529964Z"
    }
   },
   "outputs": [],
   "source": [
    "modelKNNW.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 25:__ Use the `.score()` method of modelKNNW to obtain the mean accuracy of the model in the training and the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.561200Z",
     "start_time": "2020-10-30T11:01:50.548231Z"
    }
   },
   "outputs": [],
   "source": [
    "print(modelKNNW.score(X_train, y_train))\n",
    "print(modelKNNW.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>2. KNN Imputer</font><a class=\"anchor\" id=\"third-bullet\"></a>\n",
    " [Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with real world data, we often encounter missing values in your data set.<br>\n",
    "We can use KNN to handle missing data, for example with the KNN Imputer from sklearn! The imputation for completing missing values using k-Nearest Neighbors is done by using the mean value from n_neighbors nearest neighbors found in the training set. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1:__ Import KNNImputer from sklearn.impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.775032Z",
     "start_time": "2020-10-30T11:01:50.763947Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2:__ Create a simple example dataset with some missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.796754Z",
     "start_time": "2020-10-30T11:01:50.777969Z"
    }
   },
   "outputs": [],
   "source": [
    "examples = [[1, 2, np.nan], [3, 4, 3], [np.nan, 6, 5], [8, 8, 7], [1, 4, np.nan]]\n",
    "data = pd.DataFrame(examples)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ in SKLearn, if it is found that two neighbors, neighbor k+1 and k, have identical distances but different labels, the results will depend on the ordering of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__ Using KNNImputer, create an instance called imputer with `n_neighbors=1`so we can check what happened, and fit to `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.803245Z",
     "start_time": "2020-10-30T11:01:50.799251Z"
    }
   },
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=1).fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 4:__ Use the `.transform()` method to impute the values in your selected data given the data you fitted your model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.861225Z",
     "start_time": "2020-10-30T11:01:50.820735Z"
    }
   },
   "outputs": [],
   "source": [
    "filled_data = imputer.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 5:__ Check the imputed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.871162Z",
     "start_time": "2020-10-30T11:01:50.863184Z"
    }
   },
   "outputs": [],
   "source": [
    "filled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images\\step1_k1.png\" style=\"height:180px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images\\step2_k1.png\" style=\"height:180px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images\\step3_k1.png\" style=\"height:180px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images\\step4_k1.png\" style=\"height:180px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 6:__ Try now with `n_neighbors=2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer2 = KNNImputer(n_neighbors=2).fit(data)\n",
    "filled_data2 = imputer2.transform(data)\n",
    "filled_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images\\step1_k2.png\" style=\"height:180px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images\\step2_k2.png\" style=\"height:180px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images\\step3_k2.png\" style=\"height:180px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images\\step4_k2.png\" style=\"height:180px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>3. KNN Regression (EXERCISE)</font><a class=\"anchor\" id=\"second-bullet\"></a> \n",
    "[Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1:__ Import KNeighborsRegressor from sklearn.neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.585743Z",
     "start_time": "2020-10-30T11:01:50.579683Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2:__ Import Boston Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.604694Z",
     "start_time": "2020-10-30T11:01:50.588735Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__ Assign to the object `data` the values from the boston dataset excepting the dependent variable (`medv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.660475Z",
     "start_time": "2020-10-30T11:01:50.654489Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 4:__ Assign to the object `target`the dependent variable from boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.666598Z",
     "start_time": "2020-10-30T11:01:50.662468Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 5:__ Import train_test_split from sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.675163Z",
     "start_time": "2020-10-30T11:01:50.669607Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 6:__ Split the dataset boston into X_train, X_val, y_train and y_val, defining `train_size` as 0.75 and `random_state`equal to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.685269Z",
     "start_time": "2020-10-30T11:01:50.677292Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 7:__ Using MinMaxScaler, scale the training data and the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.651202Z",
     "start_time": "2020-10-30T11:01:50.637794Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 8:__ Using KNeighborsRegressor, create an instance called modelKNN_Reg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.693283Z",
     "start_time": "2020-10-30T11:01:50.687265Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Methods in KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 9:__ Use the `.fit()`method to fit the model to the array of points `X_train` and `y_train`,i.e., associate the argument keyword `X` to `X_train` and `y` to `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.708678Z",
     "start_time": "2020-10-30T11:01:50.695630Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 10:__ Use the `.predict()` method to perform classification in `X_train` and assign to the object `labels_train`. Do the same for `X_val` and assign to the object `labels_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.730404Z",
     "start_time": "2020-10-30T11:01:50.710992Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 11:__ Use the `.score()` method of modelKNN_Reg to obtain  the coefficient of determination R^2 of the given train data `X_train` and the true labels for X, `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.748659Z",
     "start_time": "2020-10-30T11:01:50.732449Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 12:__ Use the `.score()` method to obtain the coefficient of determination R^2 of the given test data `X_val` and the true labels for X, `y_val`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T11:01:50.762916Z",
     "start_time": "2020-10-30T11:01:50.750624Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 14:__ Check the MAE (mean absolute error) obtained in the training and in validation dataset. Import the needed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 15:__ To identify the optimal number of neighbors to select, create a loop where you test the MAE in validation, where the number of neighbors range from 1 to 10. Check the number of neighbors to keep (in this case look only at the best performance in validation) and the MAE in the training and in the validation for that number of neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 16:__ Is the best solution a case of overfitting? Print this time the train and the validation MAE for all the options of neighbors (between 1 and 10) and try to understand the best option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 17:__ Create a line plot where you check the error of training and validation according to the number of neighbors, using the values obtained in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
