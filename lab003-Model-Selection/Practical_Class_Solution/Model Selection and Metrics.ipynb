{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Assessment\n",
    "\n",
    "[1 - Model Selection](#selection)\n",
    "* [1.1 - Hold-Out Method](#hold)\n",
    "* [1.2 - K-Fold](#kfold)\n",
    "* [1.3 - Repeated K-Fold](#r_kfold)\n",
    "* [1.4 - Leave-one-Out](#loo)\n",
    "* [1.5 - Other splitting techniques](#other)\n",
    "\n",
    "[2 - Performance measures](#measures)\n",
    "* [2.1 - Regression Problems](#regress)\n",
    "* [2.2 - Classification Problems](#class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"selection\">\n",
    "\n",
    "## `1. Model Selection`\n",
    "    \n",
    "</a>\n",
    "\n",
    "__`Step 1`__ Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2`__ Read the dataset __diabetes.csv__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv(r'./Datasets/diabetes.csv')\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset we have only 768 rows and 9 columns. Usually in data with this dimensionality we apply K-Fold Croo Validation.But let's see other approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 3`__ Create an object named __data__ that will contain your independent variables and another object named __target__ that will contain your dependent variable / target (the last column in the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO IT\n",
    "data = diabetes.iloc[:,:-1]\n",
    "target = diabetes.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"hold\">\n",
    "\n",
    "## 1.1. The Hold-Out Method\n",
    "\n",
    "</a>\n",
    "    \n",
    "In this approach we randomly split the full dataset into training and test sets. Then we apply the model training on the training set and use the test set for validation purpose, ideally split the data into 70:30 or 80:20. With this approach there is a possibility of high bias if we have limited data, because we would miss some information about the data which we have not used for training. If our data is huge then this approach is acceptable.\n",
    "\n",
    "In this exercise, we are going to split our dataset into train, test and validation. <br> <br>\n",
    "By default, sklearn has a function named train_test_split that allows to split the dataset into two different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 4`__ Import the library `train_test_split` from `sklearn.model_selection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO IT\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 5`__ Divide the `data`into `X_train_val` and `X_test`, the `target`into `y_train_val` and `y_test`, and define the following arguments: `test_size = 0.15`, `random_state = 15`, `shuffle = True` and `stratify = target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(data, \n",
    "                                                    target, \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=15, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=target\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will allow me to create two different datasets, one for train and validation (85% of the data) and one for test (15% of the data). <br>\n",
    "The stratification will allow me to have the same proportion of each label of the dependent variable in both datasets.\n",
    "\n",
    "\n",
    "### How to create the three datasets: train, validation and test?\n",
    "To create three datasets (train, validation and test) we are going to use the function train_test_split twice. <br><br>\n",
    "We already created in Step 5 two sets of datasets, one for test (X_test and y_test) and another one that includes the data for training and validation (X_train_val and y_train_val). <br>\n",
    "Now is time to split our biggest dataset into train and validation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Division.png\" alt=\"Drawing\" style=\"width: 500px;\"/> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 6`__  Divide the `X_train_val`into `X_train` and `X_val`, the `y_train_val` into `y_train` and `y_val`, and define the following arguments: `test_size = 0.18`, `random_state = 15`, `shuffle = True` and `stratify = y_train_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO IT\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val,\n",
    "                                                  y_train_val,\n",
    "                                                  test_size = 0.18,\n",
    "                                                  random_state = 15,\n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=y_train_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 7`__ Check the proportion of data for each dataset. _(written for you)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.7% | validation:0.15% | test:0.15%\n"
     ]
    }
   ],
   "source": [
    "print('train:{}% | validation:{}% | test:{}%'.format(round(len(y_train)/len(target),2),\n",
    "                                                     round(len(y_val)/len(target),2),\n",
    "                                                     round(len(y_test)/len(target),2)\n",
    "                                                    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have three different datasets, namely:\n",
    "- Training dataset, with 70% of the data, that will allow me to build the model;\n",
    "- Validation dataset, with 15% of the data, that will allow me to fine tune the model and check some problems like overfitting;\n",
    "- Test dataset, with 15% of the data, that will allow me to evaluate the performance of the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we apply stratification taking into account the target, our datasets are going to have similar proportions in '0s' and '1s' for all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "0    0.649813\n",
      "1    0.350187\n",
      "Name: Outcome, dtype: float64\n",
      "Validation Data\n",
      "0    0.652542\n",
      "1    0.347458\n",
      "Name: Outcome, dtype: float64\n",
      "Test Data\n",
      "0    0.655172\n",
      "1    0.344828\n",
      "Name: Outcome, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Training Data')\n",
    "print(y_train.value_counts()/len(y_train))\n",
    "print('Validation Data')\n",
    "print(y_val.value_counts()/len(y_val))\n",
    "print('Test Data')\n",
    "print(y_test.value_counts()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 8`__ What if I didn't apply stratification? Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_not_strat, X_test_not_strat, y_train_not_strat, y_test_not_strat = train_test_split(data, \n",
    "                                                    target, \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=15, \n",
    "                                                    shuffle=True, \n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "0    0.780899\n",
      "1    0.440075\n",
      "Name: Outcome, dtype: float64\n",
      "Validation Data\n",
      "0    0.703390\n",
      "1    0.279661\n",
      "Name: Outcome, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Training Data')\n",
    "print(y_train_not_strat.value_counts()/len(y_train))\n",
    "print('Validation Data')\n",
    "print(y_test_not_strat.value_counts()/len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the percentage of each possible class for boths datasets do not match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"kfold\">\n",
    "\n",
    "## 1.2. K-Fold\n",
    "\n",
    "</a>\n",
    "\n",
    "Now we are going to apply K-Fold. K-Fold is the most used strategy when splitting our data, and more appropriate when we have a medium-sized dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 9`__ Import __KFold__ from __sklearn.model_selection__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO IT\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 10`__ Create a KFold Instance where the number of splits is 10 (*n_splits*) and name it as __kf__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO IT\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time I want to apply already a machine learning algorithm on my data, so we can verify the results obtained on the different models built during the K-Fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 11`__ Import __LogisticRegression__ from __sklearn.linear_model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO IT\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 12`__ Create a function named __avg_score_LR__ that will return the average score value for the train and the test set and the standard deviation by using a logistic Regression. This will have as parameters the splitting technique you are going to use, your independent variables and your target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score_LR(split_method,X,y):\n",
    "    score_train = []\n",
    "    score_test = []\n",
    "    for train_index, test_index in split_method.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model = LogisticRegression().fit(X_train, y_train)\n",
    "        value_train = model.score(X_train, y_train)\n",
    "        value_test = model.score(X_test,y_test)\n",
    "        score_train.append(value_train)\n",
    "        score_test.append(value_test)\n",
    "\n",
    "    \n",
    "    print('Training mean accuracy for each model:', score_train)\n",
    "    print('\\nTest mean accuracy for each model:', score_test)\n",
    "    print('\\nTrain average value:' +  str(round(np.mean(score_train),2)) + '+/-' + str(round(np.std(score_train),2)))\n",
    "    print('\\nTest average value:' +  str(round(np.mean(score_test),2)) + '+/-' + str(round(np.std(score_test),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 13`__ Call the function __avg_score_LR__ and check the average score for the train and the test sets using the split technique __kf__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean accuracy for each model: [0.7988422575976846, 0.7756874095513748, 0.7756874095513748, 0.788712011577424, 0.7829232995658466, 0.7901591895803184, 0.768451519536903, 0.7742402315484804, 0.7933526011560693, 0.7803468208092486]\n",
      "\n",
      "Test mean accuracy for each model: [0.7012987012987013, 0.8441558441558441, 0.7532467532467533, 0.6883116883116883, 0.7922077922077922, 0.7402597402597403, 0.8571428571428571, 0.8181818181818182, 0.7368421052631579, 0.8026315789473685]\n",
      "\n",
      "Train average value:0.78+/-0.01\n",
      "\n",
      "Test average value:0.77+/-0.06\n"
     ]
    }
   ],
   "source": [
    "avg_score_LR(kf, data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"r_kfold\">\n",
    "\n",
    "## 1.3. Repeated K-Fold\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply Repeated K-Fold. This is a technique that, as the name says, is going to repeat the process of K-Fold several times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 14`__ Import __RepeatedKFold__ from __sklearn.model_selection__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO IT\n",
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 15`__ Create a RepeatedKFold Instance where the number of splits is 6 (`n_splits=6`) and the number of times cross-validator needs to be repeated is 2 (`n_repeats=2`)  and name it as __rkf__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO IT\n",
    "rkf = RepeatedKFold(n_splits=6, n_repeats=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 16`__ Call the function __avg_score_LR__ and check the average score for the train and the test sets using __rkf__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean accuracy for each model: [0.78125, 0.778125, 0.76875, 0.775, 0.7765625, 0.7875, 0.778125, 0.771875, 0.78125, 0.8, 0.7671875, 0.7796875]\n",
      "\n",
      "Test mean accuracy for each model: [0.7890625, 0.765625, 0.7890625, 0.7421875, 0.7890625, 0.7578125, 0.78125, 0.796875, 0.7734375, 0.6953125, 0.828125, 0.7109375]\n",
      "\n",
      "Train average value:0.78+/-0.01\n",
      "\n",
      "Test average value:0.77+/-0.04\n"
     ]
    }
   ],
   "source": [
    "# DO IT\n",
    "avg_score_LR(rkf, data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"loo\">\n",
    "\n",
    "## 1.4. Leave One Out\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 17`__ Do the same steps you applied on the previous techniques, but this time using the Leave One Out. For that, you need to import __LeaveOneOut__ from __sklearn.model_selection__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean accuracy for each model: [0.7770534550195567, 0.7796610169491526, 0.7757496740547588, 0.7770534550195567, 0.7809647979139505, 0.7796610169491526, 0.7848761408083442, 0.7835723598435462, 0.7809647979139505, 0.7822685788787483, 0.7809647979139505, 0.7809647979139505, 0.7809647979139505, 0.7822685788787483, 0.7835723598435462, 0.7796610169491526, 0.7822685788787483, 0.7835723598435462, 0.7783572359843546, 0.7822685788787483, 0.7809647979139505, 0.7822685788787483, 0.7783572359843546, 0.7835723598435462, 0.7822685788787483, 0.7835723598435462, 0.7822685788787483, 0.7757496740547588, 0.7809647979139505, 0.7809647979139505, 0.7848761408083442, 0.7822685788787483, 0.7822685788787483, 0.7861799217731421, 0.7822685788787483, 0.7796610169491526, 0.7861799217731421, 0.7835723598435462, 0.7822685788787483, 0.7809647979139505, 0.7848761408083442, 0.7848761408083442, 0.788787483702738, 0.7783572359843546, 0.7770534550195567, 0.7835723598435462, 0.7822685788787483, 0.7861799217731421, 0.7835723598435462, 0.7796610169491526, 0.7783572359843546, 0.7861799217731421, 0.7796610169491526, 0.7809647979139505, 0.7809647979139505, 0.7835723598435462, 0.7809647979139505, 0.7796610169491526, 0.7848761408083442, 0.7783572359843546, 0.7809647979139505, 0.78748370273794, 0.7822685788787483, 0.7848761408083442, 0.7835723598435462, 0.7796610169491526, 0.7822685788787483, 0.7796610169491526, 0.7848761408083442, 0.7835723598435462, 0.7822685788787483, 0.7770534550195567, 0.7796610169491526, 0.7822685788787483, 0.7796610169491526, 0.7796610169491526, 0.7757496740547588, 0.7796610169491526, 0.7757496740547588, 0.7835723598435462, 0.7796610169491526, 0.7822685788787483, 0.7835723598435462, 0.7783572359843546, 0.7848761408083442, 0.7809647979139505, 0.7796610169491526, 0.7757496740547588, 0.7861799217731421, 0.7835723598435462, 0.7809647979139505, 0.7783572359843546, 0.7848761408083442, 0.7822685788787483, 0.7809647979139505, 0.7809647979139505, 0.7809647979139505, 0.7822685788787483, 0.7835723598435462, 0.7835723598435462, 0.7822685788787483, 0.7848761408083442, 0.7809647979139505, 0.7809647979139505, 0.7796610169491526, 0.7835723598435462, 0.7809647979139505, 0.7848761408083442, 0.7822685788787483, 0.7809647979139505, 0.7796610169491526, 0.7783572359843546, 0.7822685788787483, 0.7796610169491526, 0.7835723598435462, 0.7770534550195567, 0.7822685788787483, 0.7835723598435462, 0.7809647979139505, 0.7770534550195567, 0.7809647979139505, 0.7835723598435462, 0.7744458930899609, 0.7861799217731421, 0.7822685788787483, 0.7757496740547588, 0.7770534550195567, 0.7809647979139505, 0.7822685788787483, 0.7861799217731421, 0.7796610169491526, 0.7809647979139505, 0.7809647979139505, 0.7835723598435462, 0.7796610169491526, 0.7809647979139505, 0.7822685788787483, 0.7796610169491526, 0.7783572359843546, 0.7809647979139505, 0.7835723598435462, 0.7822685788787483, 0.7822685788787483, 0.7835723598435462, 0.7796610169491526, 0.7757496740547588, 0.7809647979139505, 0.7822685788787483, 0.7835723598435462, 0.7835723598435462, 0.7809647979139505, 0.7731421121251629, 0.7848761408083442, 0.7835723598435462, 0.7770534550195567, 0.7861799217731421, 0.7848761408083442, 0.7809647979139505, 0.7822685788787483, 0.7770534550195567, 0.7835723598435462, 0.7861799217731421, 0.7809647979139505, 0.7809647979139505, 0.7822685788787483, 0.7835723598435462, 0.7835723598435462, 0.7822685788787483, 0.7835723598435462, 0.7809647979139505, 0.7809647979139505, 0.7796610169491526, 0.7848761408083442, 0.7835723598435462, 0.7822685788787483, 0.7822685788787483, 0.7783572359843546, 0.7796610169491526, 0.7809647979139505, 0.7796610169491526, 0.7783572359843546, 0.7809647979139505, 0.7783572359843546, 0.7848761408083442, 0.7848761408083442, 0.7822685788787483, 0.7744458930899609, 0.7835723598435462, 0.7848761408083442, 0.7848761408083442, 0.7809647979139505, 0.7809647979139505, 0.7835723598435462, 0.78748370273794, 0.7796610169491526, 0.7835723598435462, 0.7835723598435462, 0.7809647979139505, 0.7835723598435462, 0.7796610169491526, 0.7809647979139505, 0.7796610169491526, 0.7822685788787483, 0.7809647979139505, 0.7809647979139505, 0.7848761408083442, 0.7835723598435462, 0.7783572359843546, 0.7822685788787483, 0.7835723598435462, 0.7809647979139505, 0.7861799217731421, 0.7796610169491526, 0.7783572359843546, 0.7835723598435462, 0.7822685788787483, 0.7796610169491526, 0.7770534550195567, 0.7848761408083442, 0.7796610169491526, 0.7757496740547588, 0.7822685788787483, 0.7809647979139505, 0.7809647979139505, 0.7835723598435462, 0.7835723598435462, 0.7809647979139505, 0.7809647979139505, 0.7822685788787483, 0.7835723598435462, 0.7809647979139505, 0.7809647979139505, 0.7809647979139505, 0.7809647979139505, 0.7809647979139505, 0.7809647979139505, 0.7835723598435462, 0.7835723598435462, 0.7822685788787483, 0.7822685788787483, 0.7835723598435462, 0.7809647979139505, 0.7822685788787483, 0.7835723598435462, 0.7796610169491526, 0.7783572359843546, 0.7848761408083442, 0.7861799217731421, 0.7783572359843546, 0.7809647979139505, 0.7809647979139505, 0.7822685788787483, 0.7835723598435462, 0.7822685788787483, 0.7796610169491526, 0.7835723598435462, 0.78748370273794, 0.7809647979139505, 0.7861799217731421, 0.7822685788787483, 0.7848761408083442, 0.7809647979139505, 0.7809647979139505, 0.7822685788787483, 0.7822685788787483, 0.7822685788787483, 0.7835723598435462, 0.7861799217731421, 0.7809647979139505, 0.7835723598435462, 0.7861799217731421, 0.7822685788787483, 0.7796610169491526, 0.7783572359843546, 0.7783572359843546, 0.7809647979139505, 0.7861799217731421, 0.7809647979139505, 0.7783572359843546, 0.7822685788787483, 0.7835723598435462, 0.7822685788787483, 0.7809647979139505, 0.7809647979139505, 0.7822685788787483, 0.7822685788787483, 0.78748370273794, 0.7809647979139505, 0.7848761408083442, 0.7822685788787483, 0.7809647979139505, 0.7835723598435462, 0.7848761408083442, 0.7809647979139505, 0.7757496740547588, 0.7861799217731421, 0.7796610169491526, 0.7757496740547588, 0.7835723598435462, 0.788787483702738, 0.7783572359843546, 0.7796610169491526, 0.7796610169491526, 0.7809647979139505, 0.7822685788787483, 0.7796610169491526, 0.7783572359843546, 0.7809647979139505, 0.7822685788787483, 0.7796610169491526, 0.7822685788787483, 0.7809647979139505, 0.7835723598435462, 0.7822685788787483, 0.7796610169491526, 0.7796610169491526, 0.7822685788787483, 0.7783572359843546, 0.7809647979139505, 0.7848761408083442, 0.7809647979139505, 0.7848761408083442, 0.7848761408083442, 0.7757496740547588, 0.7783572359843546, 0.7796610169491526, 0.7848761408083442, 0.7822685788787483, 0.7848761408083442, 0.7822685788787483, 0.7796610169491526, 0.7835723598435462, 0.7822685788787483, 0.7822685788787483, 0.7796610169491526, 0.7822685788787483, 0.7835723598435462, 0.7809647979139505, 0.7809647979139505, 0.7848761408083442, 0.7809647979139505, 0.7835723598435462, 0.7809647979139505, 0.7822685788787483, 0.7809647979139505, 0.7809647979139505, 0.7770534550195567, 0.7783572359843546, 0.7861799217731421, 0.7835723598435462, 0.7783572359843546, 0.7809647979139505, 0.7809647979139505, 0.7809647979139505, 0.7809647979139505, 0.7822685788787483, 0.7822685788787483, 0.7835723598435462, 0.7822685788787483, 0.78748370273794, 0.7822685788787483, 0.7822685788787483, 0.7757496740547588, 0.7848761408083442, 0.7809647979139505, 0.7848761408083442, 0.7783572359843546, 0.7835723598435462, 0.7822685788787483, 0.7796610169491526, 0.7822685788787483, 0.7796610169491526, 0.7809647979139505, 0.7796610169491526, 0.7835723598435462, 0.7835723598435462, 0.7835723598435462, 0.7822685788787483, 0.7835723598435462, 0.7835723598435462, 0.7783572359843546, 0.7809647979139505, 0.7770534550195567, 0.7822685788787483, 0.7822685788787483, 0.7809647979139505, 0.7835723598435462, 0.7848761408083442, 0.7770534550195567, 0.7835723598435462, 0.7822685788787483, 0.7835723598435462, 0.7796610169491526, 0.7835723598435462, 0.7770534550195567, 0.7809647979139505, 0.7822685788787483, 0.7835723598435462, 0.7835723598435462, 0.7796610169491526, 0.7822685788787483, 0.7783572359843546, 0.7835723598435462, 0.7796610169491526, 0.7809647979139505, 0.7822685788787483, 0.7835723598435462, 0.7848761408083442, 0.7731421121251629, 0.7809647979139505, 0.7783572359843546, 0.7809647979139505, 0.7835723598435462, 0.7822685788787483, 0.7835723598435462, 0.7835723598435462, 0.7861799217731421, 0.7796610169491526, 0.7848761408083442, 0.7835723598435462, 0.7861799217731421, 0.7848761408083442, 0.7809647979139505, 0.7900912646675359, 0.7796610169491526, 0.7757496740547588, 0.7835723598435462, 0.7744458930899609, 0.7822685788787483, 0.78748370273794, 0.7835723598435462, 0.7783572359843546, 0.7822685788787483, 0.7848761408083442, 0.7783572359843546, 0.7822685788787483, 0.7835723598435462, 0.7822685788787483, 0.7757496740547588, 0.7822685788787483, 0.7835723598435462, 0.7809647979139505, 0.7822685788787483, 0.7809647979139505, 0.7835723598435462, 0.7809647979139505, 0.7809647979139505, 0.7822685788787483, 0.7809647979139505, 0.7822685788787483, 0.7835723598435462, 0.7796610169491526, 0.7809647979139505, 0.7835723598435462, 0.7861799217731421, 0.7809647979139505, 0.7796610169491526, 0.7861799217731421, 0.7796610169491526, 0.7822685788787483, 0.7770534550195567, 0.7835723598435462, 0.7796610169491526, 0.7861799217731421, 0.7796610169491526, 0.7822685788787483, 0.7835723598435462, 0.7770534550195567, 0.7770534550195567, 0.7822685788787483, 0.7822685788787483, 0.7822685788787483, 0.7848761408083442, 0.7822685788787483, 0.7848761408083442, 0.7822685788787483, 0.788787483702738, 0.788787483702738, 0.7796610169491526, 0.7809647979139505, 0.7822685788787483, 0.7809647979139505, 0.7822685788787483, 0.7822685788787483, 0.7783572359843546, 0.7861799217731421, 0.7783572359843546, 0.7835723598435462, 0.7783572359843546, 0.7835723598435462, 0.7822685788787483, 0.7835723598435462, 0.7809647979139505, 0.7835723598435462, 0.7770534550195567, 0.7835723598435462, 0.7835723598435462, 0.78748370273794, 0.7822685788787483, 0.7835723598435462, 0.7835723598435462, 0.7809647979139505, 0.7809647979139505, 0.7835723598435462, 0.7822685788787483, 0.7822685788787483, 0.7861799217731421, 0.7783572359843546, 0.7913950456323338, 0.7822685788787483, 0.7822685788787483, 0.7796610169491526, 0.7822685788787483, 0.7796610169491526, 0.7861799217731421, 0.7783572359843546, 0.7835723598435462, 0.7835723598435462, 0.7848761408083442, 0.7835723598435462, 0.7796610169491526, 0.7809647979139505, 0.7809647979139505, 0.7809647979139505, 0.7796610169491526, 0.7809647979139505, 0.7835723598435462, 0.7783572359843546, 0.7835723598435462, 0.7809647979139505, 0.7783572359843546, 0.7822685788787483, 0.7809647979139505, 0.7809647979139505, 0.7757496740547588, 0.7770534550195567, 0.7809647979139505, 0.7822685788787483, 0.7809647979139505, 0.7861799217731421, 0.7835723598435462, 0.7822685788787483, 0.7822685788787483, 0.7809647979139505, 0.7822685788787483, 0.7809647979139505, 0.7757496740547588, 0.7848761408083442, 0.78748370273794, 0.7848761408083442, 0.7822685788787483, 0.7809647979139505, 0.7848761408083442, 0.7809647979139505, 0.7796610169491526, 0.7796610169491526, 0.7796610169491526, 0.7822685788787483, 0.7861799217731421, 0.7796610169491526, 0.7835723598435462, 0.7822685788787483, 0.7861799217731421, 0.7835723598435462, 0.7809647979139505, 0.7835723598435462, 0.7783572359843546, 0.7809647979139505, 0.7822685788787483, 0.7848761408083442, 0.7770534550195567, 0.7770534550195567, 0.7822685788787483, 0.7809647979139505, 0.78748370273794, 0.7848761408083442, 0.7796610169491526, 0.7822685788787483, 0.7822685788787483, 0.7783572359843546, 0.788787483702738, 0.7783572359843546, 0.7822685788787483, 0.7796610169491526, 0.7809647979139505, 0.7809647979139505, 0.7822685788787483, 0.7783572359843546, 0.7822685788787483, 0.7861799217731421, 0.7796610169491526, 0.78748370273794, 0.78748370273794, 0.7835723598435462, 0.7822685788787483, 0.7861799217731421, 0.7822685788787483, 0.7848761408083442, 0.7822685788787483, 0.7809647979139505, 0.7822685788787483, 0.7822685788787483, 0.7835723598435462, 0.7731421121251629, 0.7861799217731421, 0.7809647979139505, 0.7835723598435462, 0.7822685788787483, 0.7848761408083442, 0.7809647979139505, 0.7835723598435462, 0.7822685788787483, 0.7835723598435462, 0.7783572359843546, 0.7809647979139505, 0.7796610169491526, 0.7848761408083442, 0.7757496740547588, 0.7822685788787483, 0.7835723598435462, 0.7809647979139505, 0.7783572359843546, 0.7848761408083442, 0.7848761408083442, 0.7822685788787483, 0.7861799217731421, 0.7822685788787483, 0.7809647979139505, 0.7809647979139505, 0.7809647979139505, 0.7835723598435462, 0.7809647979139505, 0.7809647979139505, 0.7822685788787483, 0.7757496740547588, 0.7822685788787483, 0.7822685788787483, 0.7809647979139505, 0.7809647979139505, 0.78748370273794, 0.7809647979139505, 0.7783572359843546, 0.7809647979139505, 0.7744458930899609, 0.7809647979139505, 0.7835723598435462, 0.7822685788787483, 0.7822685788787483, 0.7848761408083442, 0.7822685788787483, 0.7770534550195567, 0.7783572359843546, 0.7835723598435462, 0.78748370273794, 0.7809647979139505, 0.7848761408083442, 0.7822685788787483, 0.7809647979139505, 0.7835723598435462, 0.7835723598435462, 0.7835723598435462, 0.7822685788787483, 0.7770534550195567, 0.7822685788787483, 0.7835723598435462, 0.7809647979139505, 0.7796610169491526, 0.7835723598435462, 0.7809647979139505, 0.7783572359843546, 0.7731421121251629, 0.7757496740547588, 0.7822685788787483, 0.7835723598435462, 0.7796610169491526, 0.7835723598435462, 0.7796610169491526, 0.7796610169491526, 0.7770534550195567, 0.7796610169491526, 0.7809647979139505, 0.7809647979139505, 0.7809647979139505, 0.7796610169491526, 0.7809647979139505, 0.7835723598435462, 0.7783572359843546, 0.7835723598435462, 0.7796610169491526, 0.7835723598435462, 0.7835723598435462, 0.7848761408083442, 0.7796610169491526, 0.7822685788787483, 0.7757496740547588, 0.7861799217731421, 0.7783572359843546, 0.7809647979139505, 0.7796610169491526, 0.7822685788787483, 0.7835723598435462, 0.7848761408083442, 0.7809647979139505, 0.7835723598435462, 0.7809647979139505, 0.7796610169491526, 0.7809647979139505, 0.7809647979139505, 0.7822685788787483, 0.7783572359843546, 0.7796610169491526, 0.7822685788787483, 0.7822685788787483, 0.7848761408083442, 0.7783572359843546, 0.7822685788787483, 0.7796610169491526, 0.7822685788787483, 0.7835723598435462, 0.7809647979139505, 0.7809647979139505, 0.7809647979139505, 0.7783572359843546, 0.78748370273794, 0.7822685788787483, 0.7809647979139505, 0.7822685788787483, 0.7861799217731421, 0.7822685788787483, 0.7822685788787483, 0.78748370273794, 0.7796610169491526, 0.7809647979139505, 0.7809647979139505, 0.7822685788787483, 0.7835723598435462, 0.7770534550195567, 0.7770534550195567, 0.7796610169491526, 0.7835723598435462, 0.7822685788787483, 0.7809647979139505, 0.7796610169491526, 0.7835723598435462, 0.7848761408083442, 0.7796610169491526, 0.7783572359843546, 0.7796610169491526, 0.7835723598435462, 0.7848761408083442, 0.7809647979139505, 0.7809647979139505, 0.7809647979139505, 0.7796610169491526, 0.7809647979139505, 0.7848761408083442, 0.7809647979139505, 0.788787483702738, 0.7783572359843546, 0.7822685788787483, 0.7835723598435462, 0.7770534550195567, 0.7770534550195567, 0.7796610169491526, 0.7822685788787483, 0.7822685788787483, 0.7796610169491526, 0.7809647979139505]\n",
      "\n",
      "Test mean accuracy for each model: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]\n",
      "\n",
      "Train average value:0.78+/-0.0\n",
      "\n",
      "Test average value:0.78+/-0.42\n"
     ]
    }
   ],
   "source": [
    "# DO IT\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "avg_score_LR(loo, data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"other\">\n",
    "\n",
    "## 1.5. Stratified k-fold and others\n",
    "\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SkLearn you have several options to select your model, and the application is similar to the cases we saw previously.\n",
    "\n",
    "<img src=\"model_selection.png\" alt=\"Drawing\" style=\"width: 800px;\"/> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models\n",
    "\n",
    "Don't forget that the purpose of this notebook is to compare different models. In the following steps, you are going to fit your data into a DecisionTree model also, and use the __KFold__ to compare the performance of it with the Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 21`__ Import __DecisionTreeClassifier__ from __sklearn.tree__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO IT\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 22`__ Similarly to step 12, create a function named __avg_score_DT__ that will return the average score value for the train and the test set and the standard deviation by using a Decision Tree Classifier. This will have as parameters the splitting technique you are going to use, your independent variables and your target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO IT\n",
    "def avg_score_DT(method,X,y):\n",
    "    score_train = []\n",
    "    score_test = []\n",
    "    for train_index, test_index in method.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "        value_train = model.score(X_train, y_train)\n",
    "        value_test = model.score(X_test,y_test)\n",
    "        score_train.append(value_train)\n",
    "        score_test.append(value_test)\n",
    "\n",
    "    print('Training mean accuracy for each model:', score_train)\n",
    "    print('\\nTest mean accuracy for each model:', score_test)\n",
    "    print('\\nTrain average value:' +  str(round(np.mean(score_train),2)) + '+/-' + str(round(np.std(score_train),2)))\n",
    "    print('\\nTest average value:' +  str(round(np.mean(score_test),2)) + '+/-' + str(round(np.std(score_test),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 24`__ Apply KFold to the data using `n_splits = 10` and check the performance of the DecisionTree you created by calling the function __avg_score_DT__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Training mean accuracy for each model: [0.7988422575976846, 0.7756874095513748, 0.7756874095513748, 0.788712011577424, 0.7829232995658466, 0.7901591895803184, 0.768451519536903, 0.7742402315484804, 0.7933526011560693, 0.7803468208092486]\n",
      "\n",
      "Test mean accuracy for each model: [0.7012987012987013, 0.8441558441558441, 0.7532467532467533, 0.6883116883116883, 0.7922077922077922, 0.7402597402597403, 0.8571428571428571, 0.8181818181818182, 0.7368421052631579, 0.8026315789473685]\n",
      "\n",
      "Train average value:0.78+/-0.01\n",
      "\n",
      "Test average value:0.77+/-0.06\n",
      "\n",
      "Decision Tree\n",
      "Training mean accuracy for each model: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "Test mean accuracy for each model: [0.6363636363636364, 0.7792207792207793, 0.6883116883116883, 0.5974025974025974, 0.6753246753246753, 0.7142857142857143, 0.7272727272727273, 0.8051948051948052, 0.6447368421052632, 0.6710526315789473]\n",
      "\n",
      "Train average value:1.0+/-0.0\n",
      "\n",
      "Test average value:0.69+/-0.06\n"
     ]
    }
   ],
   "source": [
    "# DO IT\n",
    "\n",
    "print('Logistic Regression')\n",
    "kf_lr = KFold(n_splits=10)\n",
    "avg_score_LR(kf_lr, data, target)\n",
    "\n",
    "print('\\nDecision Tree')\n",
    "\n",
    "kf_dt = KFold(n_splits=10)\n",
    "avg_score_DT(kf_dt, data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"measures\">\n",
    "\n",
    "## `2. Performance Measures`\n",
    "    \n",
    "</a>\n",
    "\n",
    "Until this point we just saw the method __'score()'__ that we can call for every model available on sklearn. <br>\n",
    "This __'score()'__ method returns the mean accuracy for Classification problems and the R^2 for Regression problems. <br>\n",
    "But we have more metrics that can suit better for our own problem.\n",
    "\n",
    "* [2.1 - Regression Problems](#regress)\n",
    "* [2.2 - Classification Problems](#class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"regress\">\n",
    "\n",
    "## 2.1. Regression Problems\n",
    "\n",
    "</a>\n",
    "\n",
    "* [2.1.1 - $R^{2}$ Score](#rsquare)\n",
    "* [2.1.2 - Adjusted $R^{2}$ Score](#adjusted)\n",
    "* [2.1.3 - MAE](#mae)\n",
    "* [2.1.4 - RMSE](#mse)\n",
    "* [2.1.5 - MedAE](#medae)\n",
    "* [2.1.6 - The Classification Report](#cr)\n",
    "\n",
    "Import the needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, median_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 1`__ Import the dataset __Boston.csv__ and define as data the independent variables and target the dependent variable (last column) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = pd.read_csv(r'./Datasets/Boston.csv')\n",
    "data_boston = boston.iloc[:,:-1]\n",
    "target_boston = boston.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2`__ By using the method train_test_split from sklearn.model_selection, split your dataset into train(80%) and validation(20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_boston, \n",
    "                                                    target_boston, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=15, \n",
    "                                                    shuffle=True, \n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 3`__ Create an instance of LinearRegression named as lr with the default parameters and fit to your train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 4`__ Now that you have your model created, assign the predictions to y_pred, using the method predict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.80383915, 40.26470606, 23.1629741 , 22.73903454, 26.60248165,\n",
       "        6.78850771, 17.98737207, 12.90645395, 28.13880473, 15.96300504,\n",
       "       17.58476405, 22.54993315, 15.57583198, 16.42813922, 20.85701954,\n",
       "       14.4238478 ,  8.59570996,  7.00268049, 21.90974047, 10.41836313,\n",
       "       38.99970045, 13.10069505, 23.60170542, 19.36745226, 19.4704504 ,\n",
       "       19.44473926, 26.81161139, 21.94644687, 19.910743  , 19.55839769,\n",
       "       21.33408116,  7.97494586, 20.91117634, 20.17838513, 23.55157079,\n",
       "       19.3060909 , 24.34755999, 28.33114956, 20.98210245, 18.08903855,\n",
       "       28.5614124 , 36.5386986 , 20.20828082, 27.06956955, 26.23745421,\n",
       "       21.00792914, 21.1962516 , 30.55209364, 24.88050603, 20.75515688,\n",
       "       30.57871029, 15.35275076, 14.12154202, 13.92054419, 17.58306333,\n",
       "       30.23390841,  7.78156918, 29.50907892, 16.69885153, 26.35705786,\n",
       "       17.51457779, 27.86328712, 18.91817276, 29.7953683 , 34.10098499,\n",
       "       20.5512098 , 23.29515547, 18.68891381, 25.08112538, 19.35032023,\n",
       "       19.1694446 , 23.72302359, 20.74999338, 12.95808177, 34.35553821,\n",
       "       19.44274216, 36.73215655, 17.42275098, 21.05742825, 13.18082562,\n",
       "       14.94614283, 17.52275305, 36.66074388, 22.02822018, 35.41426715,\n",
       "       19.24022396, 29.39844163, 23.18394539, 26.72848257, 20.60326005,\n",
       "       30.16468966, 23.48286643, 38.66342178, 24.02603845, 27.73977974,\n",
       "       34.25622488, 15.16569515, 27.15327868, 23.3801194 , 24.19411479,\n",
       "       20.05442072, 12.31158995])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(X_val)\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"rsquare\">\n",
    "    \n",
    "### 2.1.1. $R^{2}$ Score\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score'>sklearn.metrics.r2_score(y_true, y_pred, ... )</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "R^2 (coefficient of determination) regression score function.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). \n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values; <br>\n",
    "_y_pred_: Estimated target values; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 5`__ Check the R^2 score of the model you created previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6920749038652123"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When to use?__ <br>\n",
    "When we want to measure the amount of variance in the target variable that can be explained by our model. <br>\n",
    "It gives the degree of variability in the target variable that is explained by the model or the independent variables. <br>\n",
    "If this value is 0.7, then it means that the independent variables explain 70% of the variation in the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"adjusted\">\n",
    "    \n",
    "### 2.1.2. Adjusted $R^{2}$ Score\n",
    "\n",
    "</a>\n",
    "\n",
    "There is no direct way to obtain the adjusted R^2 using sklearn, but we can apply the formula:\n",
    "<img src=\"adj_r2.png\" alt=\"Drawing\" style=\"width: 300px;\"/> <br>\n",
    "\n",
    "\n",
    "where n stands for the sample size and p for the number of the regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 6`__ Calculate the Adjusted R^2 Score for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6465859692089369"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO IT\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "n = len(y_val)\n",
    "p = len(X_train.columns)\n",
    "\n",
    "def adj_r2 (r2,n,p):\n",
    "    return 1-(1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "adj_r2(r2,n,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When to use?__ <br>\n",
    "When we want to measure the amount of variance in the target variable that can be explained by our model. <br>\n",
    "This is a form of R-squared that is adjusted for the number of terms in the model. <br>\n",
    "Tries to avoid the problem associated with R-squared:  even if we are adding redundant variables to the data, the value of R-squared does not decrease - it either remains the same or increases with the addition of new independent variables.\n",
    "\n",
    "__Then what is the advantage of $R^{2}$?__ <br>\n",
    "It has a direct interpretation as the proportion of variance in the dependent variable that is accounted for by the model.\n",
    "\n",
    "\n",
    "<hline>\n",
    "\n",
    "***\n",
    "    \n",
    "However in some cases we are more interested in quantifying the error in the same measuring unit of the variable:\n",
    "    - we can use metrics like MAE, MSE and MedAE for that.\n",
    "    \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"mae\">\n",
    "    \n",
    "### 2.1.3. MAE (Mean absolute error)\n",
    "\n",
    "</a>\n",
    "\n",
    "<img src=\"mae.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "__`Step 7`__ Check the MAE of the model you created previously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error'>sklearn.metrics.mean_absolute_error(y_true, y_pred, ... )</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Mean absolute error regression loss.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "Best possible value is 0.0. MAE is always non-negative.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values; <br>\n",
    "_y_pred_: Estimated target values; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.686086823380285"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When to use?__ <br>\n",
    "It measures the average magnitude of the errors in a set of predictions, without considering their direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"mse\">\n",
    "    \n",
    "### 2.1.4. RMSE (Root Mean squared error)\n",
    "\n",
    "</a>\n",
    "\n",
    "<img src=\"rmse.png\" alt=\"Drawing\" style=\"width: 250px;\"/>\n",
    "\n",
    "__`Step 8`__ Check the RMSE of the model you created previously\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error'>sklearn.metrics.mean_squared_error(y_true, y_pred, ... )</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Mean absolute error regression loss.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "Best possible value is 0.0. MSE is always non-negative.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values; <br>\n",
    "_y_pred_: Estimated target values; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.81224546508083"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred, squared = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When to use?__ <br>\n",
    "Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE should be more useful when large errors are particularly undesirable.\n",
    "\n",
    "__MAE vs. RMSE__ <br>\n",
    "RMSE has the benefit of penalizing large errors more so can be more appropriate in some cases, for example, if being off by 20 is more than twice as bad as being off by 10. But if being off by 20 is just twice as bad as being off by 10, then MAE is more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"medae\">\n",
    "    \n",
    "### 2.1.5. MedAE (Median absolute error)\n",
    "\n",
    "</a>\n",
    "\n",
    "__`Step 9`__ Check the MedAE score of the model you created previously\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.median_absolute_error'>sklearn.metrics.median_absolute_error(y_true, y_pred, ... )</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Median absolute error regression loss\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "Best possible value is 0.0. MedAE is always non-negative.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values; <br>\n",
    "_y_pred_: Estimated target values; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.82096468962707"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_absolute_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When to use?__ <br>\n",
    "Using the median instead of the mean implies that we are ignoring the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"class\">\n",
    "\n",
    "## 2.2. Classification Problems\n",
    "</a>\n",
    "\n",
    "* [2.2.1 - The confusion matrix](#confusion)\n",
    "* [2.2.2 - The accuracy Score](#accuracy)\n",
    "* [2.2.3 - The precision](#precision)\n",
    "* [2.2.4 - The recall](#recall)\n",
    "* [2.2.5 - The F1 Score](#f1)\n",
    "\n",
    "\n",
    "Now we are going to apply some classification metrics to the diabetes dataset. For that, we are going to import the needed packages from `sklearn.metrics`. <br>\n",
    "<br>The sklearn library offers a wide range of metrics for this situation. We are going to see the most used ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 10`__ By using the method train_test_split from sklearn.model_selection, split your dataset `diabetes` into train(70%) and validation(30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data, \n",
    "                                                  target, \n",
    "                                                  test_size = 0.3, \n",
    "                                                  random_state=5, \n",
    "                                                  stratify = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 11`__ Create an instance of LogisticRegression named as __log_model__ with the default parameters and fit to your train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 12`__ Now that you have your model created, assign the predictions to y_pred, using the method predict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO IT\n",
    "y_pred = log_model.predict(X_val)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"confusion\">\n",
    "    \n",
    "### 2.2.1. The confusion matrix\n",
    "\n",
    "</a>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix'>sklearn.metrics.confusion_matrix(y_true, y_pred, ...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Compute confusion matrix to evaluate the accuracy of a classification\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values.; <br>\n",
    "_y_pred_: Estimated targets as returned by a classifier.; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 13`__ Obtain the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[133,  17],\n",
       "       [ 38,  43]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix in sklearn is presented in the following format: <br>\n",
    "[ [ TN  FP  ] <br>\n",
    "    [ FN  TP ] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"accuracy\">\n",
    "    \n",
    "### 2.2.2. The accuracy score\n",
    "\n",
    "</a>\n",
    "\n",
    "<img src=\"accuracy.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score'>sklearn.metrics.accuracy_score(y_true, y_pred, normalize=True,...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Accuracy classification score.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "If normalize is True, then the best performance is 1. When normalize = False, then the best performance is the number of samples.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values.; <br>\n",
    "_y_pred_: Estimated targets as returned by a classifier.; <br>\n",
    "_normalize_: If False, return the number of correctly classified samples. Otherwise, return the fraction of correctly classified samples. <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 14`__ Get the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO IT\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is accuracy always a good option? Let's check with an example:\n",
    "\n",
    "<img src=\"example_1.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "In this case, what is the accuracy?\n",
    "\n",
    "<img src=\"example_2.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "We have an accuracy of 99,1% which is very very high! That is great, right? <br>\n",
    "Well, not really...<br>\n",
    "Imagine that we are testing people potentially with covid... A positive person is actually someone who is sick and carrying a virus that can spread very quickly! The cost of having a misclassified actual positive (or a false negative) is very high!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"precision\">\n",
    "    \n",
    "### 2.2.3. The precision\n",
    "\n",
    "</a>\n",
    "\n",
    "<img src=\"precision.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score'>sklearn.metrics.precision_score(y_true, y_pred, ...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Compute the precision.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "The best value is 1, and the worst value is 0.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values.; <br>\n",
    "_y_pred_: Estimated targets as returned by a classifier.; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 15`__ Get the precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7166666666666667"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the confusion matrix, we can verify that precision is only concerned to the predicted values that were considered positive:\n",
    "    \n",
    "<img src=\"example_3.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "So precision gives us how precise / accurate our model is out of those predicted positive, how many of them are actual positive.\n",
    "\n",
    "__When to use?__\n",
    "\n",
    "`When the cost of False Positives is high.` <br>\n",
    "For example, in email spam detection, where a negative is considered not spam and a positive is a spam email. <br>\n",
    "A false positive will be an email that is considered spam when in reality it was not - the user will loose potentially importante information if the precision is not high in the spam detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"recall\">\n",
    "    \n",
    "### 2.2.4. The recall\n",
    "\n",
    "</a>\n",
    "<img src=\"recall.png\" alt=\"Drawing\" style=\"width: 180px;\"/>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.recall_score'>sklearn.metrics.recall_score(y_true, y_pred, ...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Compute the recall.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "The best value is 1 and the worst value is 0.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values.; <br>\n",
    "_y_pred_: Estimated targets as returned by a classifier.; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 16`__ Get the recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5308641975308642"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the confusion matrix:\n",
    "    \n",
    "<img src=\"example_4.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Recall calculates how many of the actual positives our model is able to capture through labeling it as positive (True positive).\n",
    "\n",
    "__When to use?__\n",
    "\n",
    "`When the cost of False Negatives is high.` <br>\n",
    "For example, in the example we gave before concerning Covid tests. If a sick patient (Actual Positive) does the test and is predicted as not sick (predicted as negative), the risk will be extremely high since the sickness is contagious. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"f1\">\n",
    "    \n",
    "### 2.2.5. The F1 Score\n",
    "\n",
    "</a>\n",
    "\n",
    "<img src=\"f1.png\" alt=\"Drawing\" style=\"width: 270px;\"/>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score'>sklearn.metrics.f1_score(y_true, y_pred, ...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "F1 score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values.; <br>\n",
    "_y_pred_: Estimated targets as returned by a classifier.; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 17`__ Get the F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6099290780141844"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When to use?__\n",
    "\n",
    "F1 Score should be used when you want to seek a balance between Precision and Recall and if there is an uneven class distribution (large number of Actual Negatives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cr\">\n",
    "    \n",
    "### 2.2.6. The Classification Report\n",
    "\n",
    "</a>\n",
    "\n",
    "__`Step 18`__ To evaluate the results, we are going to use also the classification report method. <br>\n",
    "Import __classification_report__ from __sklearn.metrics__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO IT\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 19`__ Create  a function named `metrics` that will print the results of the classification report and the confusion matrix for both datasets (train and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_train, pred_train , y_val, pred_val):\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                     TRAIN                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    print(confusion_matrix(y_train, pred_train))\n",
    "\n",
    "\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                VALIDATION                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_val, pred_val))\n",
    "    print(confusion_matrix(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 20`__ Create an object named __labels_train__ that will containt the predicted values for the train and another one named __labels_val__ that will contain the predicted values for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = log_model.predict(X_train)\n",
    "labels_val = log_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 21`__ Call the function metrics() defined previously, and define the arguments: <br> (`y_train = y_train`, `pred_train = labels_train` , `y_val = y_val`, `pred_val = labels_val`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85       350\n",
      "           1       0.76      0.60      0.67       187\n",
      "\n",
      "    accuracy                           0.80       537\n",
      "   macro avg       0.78      0.75      0.76       537\n",
      "weighted avg       0.79      0.80      0.79       537\n",
      "\n",
      "[[314  36]\n",
      " [ 74 113]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83       150\n",
      "           1       0.72      0.53      0.61        81\n",
      "\n",
      "    accuracy                           0.76       231\n",
      "   macro avg       0.75      0.71      0.72       231\n",
      "weighted avg       0.76      0.76      0.75       231\n",
      "\n",
      "[[133  17]\n",
      " [ 38  43]]\n"
     ]
    }
   ],
   "source": [
    "# DO IT\n",
    "metrics(y_train = y_train, pred_train = labels_train, y_val = y_val, pred_val = labels_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
